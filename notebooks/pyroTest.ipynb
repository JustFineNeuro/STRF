{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal,AutoLowRankMultivariateNormal,AutoLaplaceApproximation,AutoIAFNormal\n",
    "from pyro.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from rfest.utils import fetch_data,build_design_matrix\n",
    "\n",
    "\n",
    "import os\n",
    "# Setting seed for reproducibility\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "def define_adjacency_matrix(n_time_bins, n_frequency_bins):\n",
    "    adjacency_matrix = np.zeros((n_time_bins * n_frequency_bins, n_time_bins * n_frequency_bins))\n",
    "\n",
    "    for i in range(n_time_bins):\n",
    "        for j in range(n_frequency_bins):\n",
    "            current_index = i * n_frequency_bins + j\n",
    "\n",
    "            # time adjacency\n",
    "            if i > 0:  # not the first time bin\n",
    "                adjacency_matrix[current_index, (i - 1) * n_frequency_bins + j] = 1\n",
    "            if i < n_time_bins - 1:  # not the last time bin\n",
    "                adjacency_matrix[current_index, (i + 1) * n_frequency_bins + j] = 1\n",
    "\n",
    "            # frequency adjacency\n",
    "            if j > 0:  # not the first frequency bin\n",
    "                adjacency_matrix[current_index, i * n_frequency_bins + j - 1] = 1\n",
    "            if j < n_frequency_bins - 1:  # not the last frequency bin\n",
    "                adjacency_matrix[current_index, i * n_frequency_bins + j + 1] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "# Define the model\n",
    "\n",
    "def model(X, Y, adjacency_matrix):\n",
    "    num_features = adjacency_matrix.shape[0]\n",
    "\n",
    "    alpha = pyro.param(\"alpha\", torch.tensor(1), constraint=dist.constraints.interval(0.0001,10000))\n",
    "    rho = pyro.param(\"rho\", torch.tensor(1.), constraint=dist.constraints.interval(0.00001,0.9999))\n",
    "\n",
    "    #multipPrec=alpha/(1-rho.pow(2))\n",
    "    #precision_matrix = torch.zeros((num_features, num_features))\n",
    "    #precision_matrix[adjacency_matrix == 1] = -rho\n",
    "    #precision_matrix[torch.eye(num_features) == 1] = 1+rho.pow(2)\n",
    "    #precision_matrix=precision_matrix*multipPrec\n",
    "\n",
    "    precision_matrix = torch.zeros((num_features, num_features))\n",
    "    precision_matrix[adjacency_matrix == 1] = rho\n",
    "    precision_matrix[torch.eye(num_features) == 1] = alpha\n",
    "\n",
    "\n",
    "\n",
    "    beta = pyro.sample(\"beta\", dist.MultivariateNormal(torch.zeros(num_features), precision_matrix=(precision_matrix)))\n",
    "\n",
    "    with pyro.plate(\"data\", len(Y)):\n",
    "        #mu = torch.exp(X.matmul(beta))  # compute the expected response using log link\n",
    "        #y = pyro.sample(\"y\", dist.Poisson(mu), obs=Y)\n",
    "        mu = X.matmul(beta)\n",
    "        #sigma = pyro.sample(\"sigma\", dist.HalfNormal(1.))\n",
    "        y = pyro.sample(\"y\", dist.Normal(mu, 1), obs=Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Generate synthetic data\n",
    "#num_features = 3\n",
    "#num_data = 1000\n",
    "#true_beta = torch.tensor([1.0, 2.0, 3.0])\n",
    "#X = torch.randn(num_data, num_features)\n",
    "#Y = torch.matmul(X, true_beta) + 0.5 * torch.randn(num_data)\n",
    "\n",
    "\n",
    "dat=fetch_data(2)\n",
    "timelags=30\n",
    "X=dat['X']\n",
    "Xdsgn = build_design_matrix(X, timelags)\n",
    "\n",
    "X=torch.tensor(Xdsgn)\n",
    "X=X.float()\n",
    "Y=torch.tensor(dat['y'])\n",
    "Y=Y.float()\n",
    "adjacency_matrix = torch.ones((X.shape[1], X.shape[1]))  # Fully connected graph\n",
    "adjacency_matrix[torch.eye(750) == 1]=2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timelags=25\n",
    "X=loadmat(os.getcwd()+'/data/X.mat')['X']\n",
    "Xdsgn = build_design_matrix(X, timelags)\n",
    "\n",
    "X=torch.tensor(Xdsgn)\n",
    "X=X.float()\n",
    "Y=torch.tensor(loadmat(os.getcwd()+'/data/y.mat')['Y'].flatten()).float()\n",
    "adjacency_matrix = torch.ones((X.shape[1], X.shape[1]))  # Fully connected graph\n",
    "adjacency_matrix[torch.eye(X.shape[1]) == 1]=2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the guide function\n",
    "#guide = AutoMultivariateNormal(model)\n",
    "guide =AutoLowRankMultivariateNormal(model)\n",
    "\n",
    "# Set up the optimizer and inference algorithm\n",
    "adam_params = {\"lr\": 0.01}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Run inference and print progress\n",
    "num_steps = 300\n",
    "for step in range(num_steps):\n",
    "    print(step)\n",
    "    loss = svi.step(X, Y, adjacency_matrix)\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step}, loss: {loss}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get parameters to compute credible intervals from posterior\n",
    "A=pyro.get_param_store()['AutoMultivariateNormal.loc'].detach()+(2.5*pyro.get_param_store()['AutoMultivariateNormal.scale'].detach())\n",
    "B=pyro.get_param_store()['AutoMultivariateNormal.loc'].detach()-(2.5*pyro.get_param_store()['AutoMultivariateNormal.scale'].detach())\n",
    "\n",
    "beta=np.array(pyro.get_param_store()['AutoMultivariateNormal.loc'].detach()).reshape(15,50)\n",
    "sns.heatmap(beta*(np.array((np.sign(A)*np.sign(B)).reshape(15,50))>0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#If we want poisson spike counts.\n",
    "\n",
    "# mu = torch.exp(X.matmul(beta))  # compute the expected response using log link\n",
    "# y = pyro.sample(\"y\", dist.Poisson(mu), obs=Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
